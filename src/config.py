"""
Durian Doctor - C·∫•u h√¨nh chung
"""
import streamlit as st
from groq import Groq
import os
from dotenv import load_dotenv

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# Global Groq client
_groq_client = None


def setup_page():
    """C·∫•u h√¨nh trang Streamlit"""
    st.set_page_config(
        page_title="Durian Doctor AI",
        page_icon="üå≥",
        layout="centered",
        initial_sidebar_state="expanded"
    )


def setup_gemini():
    """Setup Groq API (t∆∞∆°ng th√≠ch c·∫£ local v√† Streamlit Cloud)"""
    global _groq_client
    
    # Try Streamlit secrets first (for cloud deployment)
    api_key = ""
    try:
        api_key = st.secrets.get("GROQ_API_KEY", "")
    except:
        # Fallback to .env (for local development)
        api_key = os.getenv("GROQ_API_KEY", "")
    
    if api_key and not _groq_client:
        _groq_client = Groq(api_key=api_key)
    return api_key


def get_gemini_client():
    """L·∫•y Groq client instance (t√™n gi·ªØ nguy√™n ƒë·ªÉ t∆∞∆°ng th√≠ch)"""
    if not _groq_client:
        setup_gemini()
    return _groq_client


def get_gemini_model_name():
    """Tr·∫£ v·ªÅ t√™n model Groq ph√π h·ª£p
    
    Returns:
        str: Model name cho Groq API
    """
    # Llama 3.3 70B - Balance t·ªët gi·ªØa speed & quality
    # Alternatives: llama-3.1-8b-instant (nhanh h∆°n), mixtral-8x7b-32768 (context l·ªõn)
    return 'llama-3.3-70b-versatile'


