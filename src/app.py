"""
Durian Doctor - ·ª®ng d·ª•ng AI ch·∫©n ƒëo√°n b·ªánh s·∫ßu ri√™ng
Streamlit App v·ªõi Grad-CAM, RAG (Local ChromaDB) v√† Gemini Chatbot
"""

import streamlit as st
from PIL import Image
import google.generativeai as genai
import os
from dotenv import load_dotenv

# --- IMPORT MODULES ---
from rag_engine import load_vector_db
from model_utils import load_model, predict_and_gradcam, CLASS_NAMES_VI

# Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Durian Doctor", 
    page_icon="üå≥", 
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- SETUP GEMINI API ---
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# --- GIAO DI·ªÜN CH√çNH (UI) ---
def main():
    st.title("üå≥ Durian Doctor AI")
    st.markdown("**H·ªá th·ªëng AI ch·∫©n ƒëo√°n b·ªánh s·∫ßu ri√™ng & T∆∞ v·∫•n ƒëi·ªÅu tr·ªã**")
    st.markdown("---")
    
    # Load t√†i nguy√™n (kh√¥ng hi·ªÉn th·ªã warning ·ªü ƒë√¢y)
    model, model_loaded = load_model()
    vector_db = load_vector_db()

    tab1, tab2 = st.tabs(["üì∑ Ch·∫©n ƒëo√°n b·ªánh", "üí¨ H·ªèi ƒë√°p AI"])
    
    # === TAB 1: CH·∫®N ƒêO√ÅN ===
    with tab1:
        # Hi·ªÉn th·ªã th√¥ng b√°o model trong tab n√†y th√¥i
        if not model_loaded:
            st.info("‚ÑπÔ∏è **Ch·ª©c nƒÉng ch·∫©n ƒëo√°n ·∫£nh ch∆∞a s·∫µn s√†ng**  \nModel AI ƒëang ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng s·ª≠ d·ª•ng tab **H·ªèi ƒë√°p AI** ƒë·ªÉ t∆∞ v·∫•n.")
            st.markdown("---")
        
        st.subheader("üì∑ T·∫£i ·∫£nh l√™n ƒë·ªÉ ch·∫©n ƒëo√°n")
        option = st.radio("Ngu·ªìn ·∫£nh:", ("üìÅ T·∫£i ·∫£nh", "üì∏ Ch·ª•p ·∫£nh"), horizontal=True)
        
        image = None
        if option == "üì∏ Ch·ª•p ·∫£nh":
            camera_file = st.camera_input("Ch·ª•p ·∫£nh")
            if camera_file: image = Image.open(camera_file).convert('RGB')
        else:
            uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "png", "jpeg"])
            if uploaded_file: image = Image.open(uploaded_file).convert('RGB')
        
        if image:
            col1, col2 = st.columns(2)
            with col1: st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
            
            if st.button("üîç Ch·∫©n ƒëo√°n ngay", type="primary"):
                if model_loaded:
                    with st.spinner('üîÑ ƒêang ph√¢n t√≠ch...'):
                        label, conf, heatmap, top3 = predict_and_gradcam(image, model)
                        
                        with col2: st.image(heatmap, caption="Heatmap v√πng b·ªánh", use_container_width=True)
                        
                        st.markdown("---")
                        st.success(f"üéØ **{CLASS_NAMES_VI.get(label, label)}** (ƒê·ªô tin c·∫≠y: {conf*100:.1f}%)")
                        
                        with st.expander("Xem chi ti·∫øt x√°c su·∫•t"):
                            for n, p in top3: st.write(f"- {CLASS_NAMES_VI.get(n, n)}: {p*100:.1f}%")
                        
                        # L∆∞u tr·∫°ng th√°i ƒë·ªÉ Chatbot bi·∫øt
                        st.session_state['diagnosis_vi'] = CLASS_NAMES_VI.get(label, label)
                else:
                    st.error("Ch∆∞a load ƒë∆∞·ª£c model.")

    # === TAB 2: CHATBOT RAG ===
    with tab2:
        st.subheader("üí¨ H·ªèi ƒë√°p v·ªõi Chuy√™n gia AI")
        
        # Toggle hi·ªÉn th·ªã qu√° tr√¨nh suy nghƒ©
        show_thinking = st.toggle("üß† Hi·ªÉn th·ªã qu√° tr√¨nh suy nghƒ©", value=False, help="Xem AI ƒëang l√†m g√¨")
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ch·∫©n ƒëo√°n g·∫ßn nh·∫•t (n·∫øu c√≥)
        if 'diagnosis_vi' in st.session_state:
            st.info(f"üìã K·∫øt qu·∫£ ch·∫©n ƒëo√°n g·∫ßn nh·∫•t: **{st.session_state['diagnosis_vi']}**")
        
        # Chat History
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Container cho messages v·ªõi chi·ªÅu cao c·ªë ƒë·ªãnh ƒë·ªÉ input lu√¥n ·ªü d∆∞·ªõi
        chat_container = st.container(height=450)
        
        # Hi·ªÉn th·ªã messages trong container
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
        
        # Input lu√¥n ·ªü d∆∞·ªõi c√πng
        prompt = st.chat_input("H·ªèi v·ªÅ b·ªánh s·∫ßu ri√™ng, c√°ch ƒëi·ªÅu tr·ªã...")
        
        if prompt:
            # Th√™m message user v√†o history
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # Hi·ªÉn th·ªã trong container
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
            
                # X·ª≠ l√Ω v√† hi·ªÉn th·ªã response
                with st.chat_message("assistant"):
                    if not GOOGLE_API_KEY:
                        st.warning("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh API Key trong ph·∫ßn Settings.")
                    else:
                        # Container cho thinking process
                        thinking_container = st.empty()
                    
                    # === STEP 1: T√¨m ki·∫øm RAG ===
                    if show_thinking:
                        with thinking_container.container():
                            st.markdown("üîç **ƒêang t√¨m ki·∫øm trong c∆° s·ªü tri th·ª©c...**")
                            with st.status("Truy v·∫•n RAG Database", expanded=True) as status:
                                st.write("üìö K·∫øt n·ªëi ChromaDB...")
                    
                    retrieved_block = ""
                    retrieved_docs_display = []
                    try:
                        if vector_db:
                            docs = vector_db.similarity_search(prompt, k=3)
                            if docs:
                                for i, d in enumerate(docs):
                                    retrieved_docs_display.append(f"**[{i+1}]** {d.page_content[:150]}...")
                                content_list = [f"[{i+1}] {d.page_content}" for i, d in enumerate(docs)]
                                retrieved_block = "TH√îNG TIN THAM KH·∫¢O T·ª™ T√ÄI LI·ªÜU (RAG):\n" + "\n\n".join(content_list)
                    except Exception as e:
                        print(f"RAG Error: {e}")
                    
                    if show_thinking:
                        with thinking_container.container():
                            with st.status("Truy v·∫•n RAG Database", expanded=True, state="complete") as status:
                                if retrieved_docs_display:
                                    st.write("‚úÖ T√¨m th·∫•y t√†i li·ªáu li√™n quan:")
                                    for doc in retrieved_docs_display:
                                        st.caption(doc)
                                else:
                                    st.write("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y t√†i li·ªáu c·ª• th·ªÉ")
                    
                    # === STEP 2: Chu·∫©n b·ªã context ===
                    if show_thinking:
                        with thinking_container.container():
                            with st.status("Truy v·∫•n RAG Database", expanded=False, state="complete"):
                                st.write("‚úÖ Ho√†n t·∫•t")
                            with st.status("X√¢y d·ª±ng ng·ªØ c·∫£nh", expanded=True) as status:
                                st.write("üìù Ph√¢n t√≠ch l·ªãch s·ª≠ h·ªôi tho·∫°i...")
                    
                    diag_context = ""
                    if 'diagnosis_vi' in st.session_state:
                        diag_context = f"L∆ØU √ù NG·ªÆ C·∫¢NH: Ng∆∞·ªùi d√πng v·ª´a upload ·∫£nh v√† ƒë∆∞·ª£c AI ch·∫©n ƒëo√°n c√¢y b·ªã b·ªánh: {st.session_state['diagnosis_vi']}."

                    chat_history_text = ""
                    recent_msgs = st.session_state.messages[-6:]
                    for msg in recent_msgs:
                        role_label = "Ng∆∞·ªùi d√πng" if msg["role"] == "user" else "Durian Doctor"
                        chat_history_text += f"{role_label}: {msg['content']}\n"

                    system_prompt = """
B·∫°n l√† "Durian Doctor" - chuy√™n gia n√¥ng nghi·ªáp h√†ng ƒë·∫ßu v·ªÅ c√¢y s·∫ßu ri√™ng t·∫°i Vi·ªát Nam.

QUY T·∫ÆC C·ªêT L√ïI (B·∫ÆT BU·ªòC):
1. **KI·ªÇM TRA L·ªäCH S·ª¨ CHAT (Context Awareness):** Tr∆∞·ªõc khi h·ªèi l·∫°i ng∆∞·ªùi d√πng, H√ÉY ƒê·ªåC K·ª∏ ph·∫ßn "L·ªäCH S·ª¨ TR√í CHUY·ªÜN" b√™n d∆∞·ªõi. N·∫øu ng∆∞·ªùi d√πng ƒë√£ cung c·∫•p th√¥ng tin (nh∆∞ tu·ªïi c√¢y, gi·ªëng, giai ƒëo·∫°n) ·ªü c√°c c√¢u tr∆∞·ªõc, **TUY·ªÜT ƒê·ªêI KH√îNG H·ªéI L·∫†I**. H√£y t·ª± x√¢u chu·ªói th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi.
2. **T∆∞ v·∫•n c√≥ t√¢m:** N·∫øu ng∆∞·ªùi d√πng h·ªèi chung chung (VD: "B√≥n ph√¢n g√¨?"), h√£y h·ªèi th√™m 2-3 th√¥ng tin quan tr·ªçng nh·∫•t (Tu·ªïi c√¢y, Giai ƒëo·∫°n sinh tr∆∞·ªüng, T√¨nh tr·∫°ng ƒë·∫•t) ƒë·ªÉ t∆∞ v·∫•n ch√≠nh x√°c.
3. **An to√†n:** Ch·ªâ ƒë∆∞a ra t√™n thu·ªëc/li·ªÅu l∆∞·ª£ng n·∫øu c√≥ trong t√†i li·ªáu. Kh√¥ng b·ªãa s·ªë. Ch·ªâ tr·∫£ l·ªùi v·ªÅ s·∫ßu ri√™ng.

C·∫§U TR√öC TR·∫¢ L·ªúI:
- Ch√†o h·ªèi ng·∫Øn g·ªçn.
- N·∫øu thi·∫øu th√¥ng tin -> H·ªèi l·∫°i.
- N·∫øu ƒë·ªß th√¥ng tin -> ƒê∆∞a ra ph√°c ƒë·ªì chi ti·∫øt (Ph√¢n b√≥n, Thu·ªëc, C√°ch l√†m) d·ª±a tr√™n "TH√îNG TIN THAM KH·∫¢O".
"""
                    
                    full_prompt = f"""
{system_prompt}

{retrieved_block}

{diag_context}

L·ªäCH S·ª¨ TR√í CHUY·ªÜN (CONTEXT):
{chat_history_text}

NG∆Ø·ªúI D√ôNG H·ªéI (C√ÇU M·ªöI NH·∫§T):
{prompt}
"""
                    
                    # === STEP 3: G·ªçi Gemini ===
                    if show_thinking:
                        with thinking_container.container():
                            with st.status("Truy v·∫•n RAG Database", expanded=False, state="complete"):
                                st.write("‚úÖ Ho√†n t·∫•t")
                            with st.status("X√¢y d·ª±ng ng·ªØ c·∫£nh", expanded=False, state="complete"):
                                st.write("‚úÖ Ho√†n t·∫•t")
                            with st.status("ü§ñ Gemini ƒëang suy nghƒ©...", expanded=True) as status:
                                st.write("üí≠ Ph√¢n t√≠ch c√¢u h·ªèi v√† t√†i li·ªáu...")
                    
                    try:
                        model_gemini = genai.GenerativeModel('gemini-2.0-flash')
                        response = model_gemini.generate_content(full_prompt)
                        bot_reply = response.text
                    except Exception as e:
                        bot_reply = f"‚ö†Ô∏è L·ªói k·∫øt n·ªëi Google Gemini: {e}"
                    
                    # === Ho√†n t·∫•t - Hi·ªÉn th·ªã k·∫øt qu·∫£ ===
                    if show_thinking:
                        with thinking_container.container():
                            with st.status("Truy v·∫•n RAG Database", expanded=False, state="complete"):
                                st.write("‚úÖ Ho√†n t·∫•t")
                            with st.status("X√¢y d·ª±ng ng·ªØ c·∫£nh", expanded=False, state="complete"):
                                st.write("‚úÖ Ho√†n t·∫•t")
                            with st.status("ü§ñ Gemini ƒëang suy nghƒ©...", expanded=False, state="complete"):
                                st.write("‚úÖ ƒê√£ t·∫°o c√¢u tr·∫£ l·ªùi")
                            st.markdown("---")
                    else:
                        thinking_container.empty()
                    
                    # Hi·ªÉn th·ªã response
                    st.markdown(bot_reply)
                    
                    # Hi·ªÉn th·ªã tr√≠ch d·∫´n ngu·ªìn t√†i li·ªáu (n·∫øu c√≥)
                    if retrieved_docs_display:
                        with st.expander("üìö Ngu·ªìn t√†i li·ªáu tham kh·∫£o", expanded=False):
                            for i, doc in enumerate(retrieved_docs_display):
                                st.markdown(doc)
                                if i < len(retrieved_docs_display) - 1:
                                    st.divider()
                    
                    # L∆∞u message
                    st.session_state.messages.append({"role": "assistant", "content": bot_reply})

    # Footer
    st.markdown(
    """
    <hr style="margin-top: 40px; border: 0; border-top: 1px solid #e0e0e0;">
    <div style='text-align: center; color: #666; font-family: sans-serif; padding: 20px 0;'>
        <p style='font-size: 16px; font-weight: 600; margin-bottom: 8px;'>
            üå≥ Durian Doctor AI
        </p>
        <p style='font-size: 14px; margin-bottom: 8px;'>
            H·ªá th·ªëng AI h·ªó tr·ª£ ch·∫©n ƒëo√°n b·ªánh s·∫ßu ri√™ng ‚Äî Ti·ªÉu Lu·∫≠n T·ªët Nghi·ªáp
        </p>
        <p style='font-size: 13px; margin-bottom: 12px;'>
            Ph√°t tri·ªÉn b·ªüi <b style='color: #333;'>ƒê·∫∑ng Anh Ki·ªát</b> &copy; 2025
        </p>
        <p style='font-size: 12px; color: #999;'>
            <i>Powered by <b>MobileNetV2</b> ‚Ä¢ <b>Grad-CAM</b> ‚Ä¢ <b>Google Gemini</b> ‚Ä¢ <b>Streamlit</b></i>
        </p>
    </div>
    """,
    unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()